---
title: "Figure1"
author: "Devi Veytia"
date: "2023-12-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Figure description/overview

This figure shows the Distribution of research across OROs and its time evolution

Panel A: Line plot of # articles for each ORO branch and Ocean & climate research by year     
Panel B: Barplot of # articles for each ORO type, filled by % articles in IPCC report. Perhaps also label at the top of the bar the year of the inflexion point of the exponential relationship    

*Key messages:*
1. there is exponential increase in research effort / articles on OROs  
? comparator : total number of articles on climate & Ocean / WoS query)	ðŸ¡ª(Panel a)
 
2. Research effort on OROs is dominated by articles on Renewable energy (50%)  (Panel b). Comparator IPCC ref list â€“ hypothesize there will be very few on renewable energy but much more on NbS

3. Contrasted trends in research effort for the different OROs types (Panel b). 



# Set up

```{r load libraries}
library(dplyr)
library(dbplyr)
library(broom)
library(R.utils)
library(RSQLite)
library(ggplot2)

#addTaskCallback(function(...) {set.seed(123);TRUE})
```


```{r Get the latest version of sqlite database and connect}

sqliteDir <- here::here("data/sqlite-databases")
sqliteFiles <- dir(sqliteDir)
sqliteVersions <- as.numeric(gsub(".sqlite","",substring(sqliteFiles, regexpr("_v", sqliteFiles) + 2)))
latestVersion <- sqliteFiles[which.max(sqliteVersions)]
dbcon <- RSQLite::dbConnect(RSQLite::SQLite(), file.path(sqliteDir, latestVersion), create=FALSE)
```


```{r import common aesthetics}
factor_aes <- readxl::read_excel(here::here("R/factor_aesthetics.xlsx"))

```

```{r import the summary of model scores}
modelScoresFileName <- dir(here::here("data"))
modelScoresFileName <- modelScoresFileName[grep("model_scores", modelScoresFileName)]

if(length(modelScoresFileName) > 1){
  versionScores <- as.Date(gsub(".csv","", gsub("summary_model_scores_","",modelScoresFileName)))
  modelScoresFileName <- modelScoresFileName[which.max(versionScores)]
}

modelScores <- readr::read_csv(here::here("data", paste(modelScoresFileName)))

```

```{r set the threshold level where an article is deemed relevant}

thresholdLevel <- 0.5

```

# Panel A: Line plot of # articles for each ORO branch and Ocean & climate research by year

For each year, and for each branch, count the number of lower, mean and upper articles relevant for each branch
```{r Sum n articles per oro branch per year}
predRel <- tbl(dbcon, "pred_relevance") 
pred_oro_branch <- tbl(dbcon, "pred_oro_branch")
uniquerefs <- tbl(dbcon, "uniquerefs")

oro_branch_by_year <- pred_oro_branch %>%
  inner_join(predRel %>% select(analysis_id, relevance_mean), by = "analysis_id")%>%
  filter(thresholdLevel <= relevance_mean) %>%
  inner_join(uniquerefs %>% select(analysis_id, year), by = "analysis_id") %>%
  group_by(year) %>%
  summarise(
    Mitigation_mean = sum(thresholdLevel <= `oro_branch.Mitigation - mean_prediction`),
    Mitigation_lower = sum(thresholdLevel <= `oro_branch.Mitigation - lower_pred`),
    Mitigation_upper = sum(thresholdLevel <= `oro_branch.Mitigation - upper_pred`),
    Nature_mean = sum(thresholdLevel <= `oro_branch.Nature - mean_prediction`),
    Nature_lower = sum(thresholdLevel <= `oro_branch.Nature - lower_pred`),
    Nature_upper = sum(thresholdLevel <= `oro_branch.Nature - upper_pred`),
    Societal_mean = sum(thresholdLevel <= `oro_branch.Societal - mean_prediction`),
    Societal_lower = sum(thresholdLevel <= `oro_branch.Societal - lower_pred`),
    Societal_upper = sum(thresholdLevel <= `oro_branch.Societal - upper_pred`)
  ) %>% 
  collect()

# Melt and reformat so each line is a yearxbranch, and then columns for mean, lower and upper
variables <- c("Mitigation","Nature","Societal")

for(v in 1:length(variables)){
  sub <- oro_branch_by_year[,c(1,grep(variables[v], colnames(oro_branch_by_year)))]
  colnames(sub) <- gsub(paste0(variables[v],"_"),"", colnames(sub))
  # sub <- reshape2::melt(sub, id.vars = "year", variable.name = "prediction_boundary", 
  #                       value.name = "n_articles")
  sub$ORO_branch <- paste(variables[v])
  if(v==1){
    oro_branch_by_year_sums <- sub
  }else{
    oro_branch_by_year_sums <- rbind(oro_branch_by_year_sums, sub)
  }
}


# Factor and format
oro_branch_by_year_sums <- oro_branch_by_year_sums%>%
  na.omit() %>%
  mutate(year = as.Date(paste0(year, "-01-01")),
         ORO_branch = factor(ORO_branch, levels = variables))

varAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
varAES <- varAES[order(varAES$order),]
oro_branch_by_year_sums$ORO_branch <- factor(
  oro_branch_by_year_sums$ORO_branch,
  levels = varAES$level, labels = varAES$label
)

summary(oro_branch_by_year_sums)


# Remove incomplete year
oro_branch_by_year_sums <- oro_branch_by_year_sums %>%
  filter(year < as.Date("2023-01-01"))


# use the max year to set the x limits
xmax = max(oro_branch_by_year_sums$year)
xmin = min(oro_branch_by_year_sums$year)
```

```{r get number of articles from citation indexed databases}

## Web of Science
wos_by_year <- read.delim2(
  here::here("data/external/ocean-and-climate-publications/WOS_ocean-and-climate_by-year_2023-11-21.txt"))

wos_by_year <- wos_by_year %>%
  rename(year = Publication.Years, n_articles = Record.Count)%>%
  select(year, n_articles)%>%
  mutate(year = as.Date(paste0(year, "-01-01"))) %>%
  filter(xmin <= year & year <= xmax) %>%
  na.omit()


## Scopus
scopus_by_year <- read.csv(
  here::here("data/external/ocean-and-climate-publications/SCOPUS_ocean-and-climate_by-year_2023-11-21.csv"))

scopus_by_year <- scopus_by_year %>%
  mutate(year = as.Date(paste0(year, "-01-01"))) %>%
  filter(xmin <= year & year <= xmax)%>%
  na.omit()


```

```{r get the timeline of policy moments decide not to include this after all, eval = FALSE}

# policyTimeline <- readxl::read_xlsx(here::here("data/external/policyMoments.xlsx"))
# policyTimeline$year <- as.Date(paste0(policyTimeline$year,"-01-01"))
# policyTimeline <- merge(policyTimeline, wos_by_year, bu="year") 
```


```{r PLOT PANEL A}

# Join branch labels with model scores to add F1 statistic to label
branchLabels <- merge(factor_aes[which(factor_aes$variable == "ORO_branch"),],
                      modelScores%>% filter(model == "oro_branch") %>% select(`label name`, `F1 - label`),
                      by.x = "level", by.y = "label name")%>%
  mutate(branchLabelF1 = paste0(label,", F1 = ", signif(`F1 - label`, 2)))


# Plot
fig1_A_ggp <- ggplot()+
  
  # Plot complete years
  geom_ribbon(data = oro_branch_by_year_sums, 
              aes(x=year, ymin = log(lower), ymax=log(upper), fill = ORO_branch), alpha = 0.5)+
  geom_line(data = oro_branch_by_year_sums, aes(x=year, y=log(mean), col=ORO_branch), linewidth = 1,
            na.rm=T)+
  geom_line(data = wos_by_year, 
            aes(x=year, y=log(n_articles), linetype = "WOS"), col="black", linewidth = 1,
            na.rm=T)+
  geom_line(data = scopus_by_year, 
            aes(x=year, y=log(n_articles), linetype = "Scopus"), col="black", linewidth = 1,
            na.rm=T)+
  
  # # Add policy moments
  # geom_vline(data=policyTimeline, aes(xintercept = year), col="red", linewidth=0.5)+
  # geom_text(data=policyTimeline, aes(x = year, y=log(n_articles), label = stringr::str_wrap(event_name,14)), 
  #           col="red", angle = 90,size=2, vjust=1, hjust=1, nudge_x = 100, nudge_y = -0.5)+
  
  
  # Format scales
  scale_color_manual(values = varAES$colour, 
                     breaks = factor_aes$label[which(factor_aes$variable == "ORO_branch")],
                     labels = branchLabels$branchLabelF1,## this line adds F1 statistic to label
                     name = "ORO branch", guide=guide_legend(order=1, nrow=3), position = "top")+
  scale_fill_manual(values = factor_aes$colour[which(factor_aes$variable == "ORO_branch")],
                    breaks = factor_aes$label[which(factor_aes$variable == "ORO_branch")], 
                    labels = branchLabels$branchLabelF1, # this line adds F1 statistic to label
                    guide = "none")+
  scale_linetype_manual(values = c("solid","dotted"), name = "Oceans & climate literature\ndatabase:",
                        guide=guide_legend(order=2, nrow=2), position = "bottom")+
  labs(x="Year", y="log(N articles)")+
  scale_x_date(limits = c(as.Date("1980-01-01"),as.Date("2022-12-31")))+
  scale_y_continuous(sec.axis = sec_axis(trans = exp, name = "N articles", 
                                         breaks = c(0,100,1000,10000,30000,80000),
                                         labels = function(x) formatC(x, big.mark=",", format="d")),
                     breaks = seq(0,10, by= 2))+ #, limits = c(0,13)
  
  theme_classic()+
  theme(
    legend.position = "bottom",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )

fig1_A_ggp
```

## Panel A supplementary analyses and figures

```{r supplement - model temporal trends}
library(nlme)
library(mgcv)


## 1/ Format dataset
by_dataset <- rbind(oro_branch_by_year_sums %>% 
                      rename(Dataset = ORO_branch, n_articles = mean) %>%
                      select(year, n_articles, Dataset),
  scopus_by_year %>% mutate(Dataset = paste("Scopus")),
  wos_by_year %>% mutate(Dataset = paste("WOS"))) %>%
  mutate(year = as.numeric(format(year, "%Y")),
         log_articles = log(n_articles)) %>%
  filter(is.finite(log_articles)) %>% 
  group_by(Dataset) %>%
  arrange(year) %>%
  ungroup()

# check that this looks right
ggplot(by_dataset, aes(year, log_articles, col = Dataset))+geom_line()






## 2/ Fit individual models for exploration


## Fit a gls with AR1 correlation -- seperate model for each dataset
gls_corAR1_fit <- function(dat){
  gls(log_articles ~ year, data = dat, correlation=corAR1())
}

modFits <- lapply(split(by_dataset, by_dataset$Dataset), gls_corAR1_fit)

summaryTable <- do.call(rbind, lapply(modFits, function(x) summary(x)$tTable['year',]))
summaryTable <- summaryTable %>% as.data.frame %>% arrange(desc(Value))
summaryTable
# the phi values for the corAR1
phis <- lapply(modFits, function(x) coef(x$modelStruct$corStruct, unconstrained = FALSE))
phis <- do.call(rbind, phis) 
phis


## Try using auto.arima to estimate the rho and phi for each time series to compare if the autocorrelation differs
# They do, but its difficult to interpret and no real 'significance' to compare
library(forecast)

my_auto_arima <- function(dat){
  dat <- dat %>% arrange(year)
  # fill in yearly gaps as NAs
  all_years <- data.frame(year = seq(min(dat$year), max(dat$year)))
  dat <- all_years %>% left_join(dat, by="year")
  auto.arima(dat$log_articles)
}

modFitsAutoArima <- lapply(split(by_dataset, by_dataset$Dataset), my_auto_arima)
modFitsAutoArima





## 3/ Test for difference in temporal trends

## 3.1/ Granger test
# Use granger test to see if the Scopus timeseries caues the trends in each of the branch-specific time series
# H0: Scopus trends DO NOT cause time series for ORO_branch 
# HA: Scopus trends DO cause time series for ORO_branch 
# But not really what I'm looking for -- not looking to assess causality in any direction, more to see if the trends
# are just significantly different

## Data for testing
by_dataset_branch <- by_dataset%>%
  filter(Dataset %in% c("Mitigation","Natural resilience","Societal adaptation")) %>%
  droplevels()

Y = by_dataset_branch[which(by_dataset_branch$Dataset == "Natural resilience"),]
with(Y, plot(year, log_articles))

grangertest_fit <- function(Y){
  X <- by_dataset[which(by_dataset$Dataset == "Scopus"),]
  dat <- merge(X, Y, by = 'year', all=TRUE) %>% arrange(year) %>% filter(1980 <= year)
  lmtest::grangertest(dat$log_articles.x,dat$log_articles.y, na.action = na.omit, order = 1)
}

grangerTests <- lapply(split(by_dataset_branch, by_dataset_branch$Dataset), grangertest_fit)
do.call(rbind, lapply(grangerTests, function(x) x$`Pr(>F)`[2])) %>% formatC(digits = 2)
# odd that HA is significant for all



## 3.2/ GLS model with dataset as a factor
# To compare regression slopes (starting in year 1980 because data before is sparse), treat the Dataset as a factor, and main interest is in the interaction between year:Dataset.

by_dataset2 <- by_dataset %>%
  filter(Dataset != "WOS") %>%
  droplevels() %>%
  mutate(Dataset = factor(Dataset, levels = c("Scopus","Mitigation","Natural resilience","Societal adaptation")))

all_fit <- gls(log_articles ~ year*Dataset, data = by_dataset2 %>% filter(1980 <= year), correlation=corAR1(form=~year|Dataset))
all_fit_sum <- summary(all_fit)

trendCoeff <- all_fit_sum$tTable[c("year","year:DatasetMitigation","year:DatasetNatural resilience","year:DatasetSocietal adaptation"),c("Value","p-value")] %>% as.data.frame()
trendCoeff$Dataset <- rownames(trendCoeff)

trendCoeff$Value_abs <- trendCoeff$Value
trendCoeff$Value_abs[which(trendCoeff$Dataset != "year")] <- trendCoeff$Value[which(trendCoeff$Dataset == "year")]+trendCoeff$Value[which(trendCoeff$Dataset != "year")]
trendCoeff$Value_abs_exp <- exp(trendCoeff$Value_abs) # Compare and the Value_abs column produces similar results to the gls fit to each dataset individually 
rownames(trendCoeff) <- NULL
trendCoeff <- trendCoeff[,c("Dataset","Value","Value_abs","Value_abs_exp","p-value")]
trendCoeff$`p-value` <- ifelse(trendCoeff$`p-value` <= 0.05, 
                               paste(formatC(trendCoeff$`p-value`, digits = 2),"*", collpase=""),
                               paste(formatC(trendCoeff$`p-value`, digits = 2)))
trendCoeff$Dataset <- c("Scopus","Mitigation","Natural resilience","Societal adaptation")
print(trendCoeff)
#               Dataset       Value  Value_abs Value_abs_exp    p-value
# 1              Scopus 0.078531447 0.07853145      1.081697 7.5e-08 * 
# 2          Mitigation 0.009208354 0.08773980      1.091704       0.64
# 3  Natural resilience 0.074701318 0.15323276      1.165596 0.00021 * 
# 4 Societal adaptation 0.062577907 0.14110935      1.151551  0.0029 * 

# Finding: So mitigation is not significantly different, but that's because it's the overall trend and does not account for the change in slope -- need a smoothing term

# Write all model output
sink(here::here("outputs/glsOROBranchTemporalTrendModelSummary.txt"))
print(all_fit_sum)
sink()


# 3.3/ Correlation
# Considering no difference between mitigation and Scopus, maybe it's more accurate to look at correlation -- no correlation is very high for all time series
cor_fit <- function(Y){
  X <- by_dataset[which(by_dataset$Dataset == "Scopus"),]
  dat <- merge(X, Y, by = 'year', all=TRUE) %>% arrange(year)
  dat <- dat %>%
    select(year, log_articles.x, log_articles.y) %>%
    na.omit()
  cor(dat$log_articles.x, dat$log_articles.y)
}

corToScopus <- lapply(split(by_dataset_branch, by_dataset_branch$Dataset), cor_fit)
unlist(corToScopus)
         # Mitigation  Natural resilience Societal adaptation 
         #  0.9332444           0.9724696           0.9606556 



## 3.4/ Gamm smooth over time to capture differences in non-linearity
# An alternative method of recognising that the trend may not be perfectly linear is to fit a GAM to fit a smooth temporal trend and AR1 correlation structure

# Format data so 0 values are kept in -- don't need to worry about infinite values because using link function
by_dataset3 <- rbind(oro_branch_by_year_sums %>% 
                      rename(Dataset = ORO_branch, n_articles = mean) %>%
                      select(year, n_articles, Dataset),
  scopus_by_year %>% mutate(Dataset = paste("Scopus")),
  wos_by_year %>% mutate(Dataset = paste("WOS"))) %>%
  mutate(year = as.numeric(format(year, "%Y"))) %>%
  group_by(Dataset) %>%
  arrange(year) %>%
  ungroup()

# Fit separate gams to explore
my_gamm <- function(dat){
  gamm(n_articles ~ s(year),correlation=corAR1(),data=dat, family = poisson())
}
modFitsGamm <- lapply(split(by_dataset, by_dataset$Dataset), my_gamm)
plot(modFitsGamm$Mitigation$gam)

# Fit gams with dataset as a grouping factor
# NB have to add Dataset as fixed term as well, otherwise the smooths don't look sensible
gammFit <- gamm(n_articles ~ s(year, by = Dataset)+Dataset, correlation=corAR1(form=~year|Dataset),
                family = poisson(link = "log"),
                data=by_dataset3 %>% filter(Dataset != "WOS") %>% droplevels())
anova(gammFit$gam) # all are significant

plot(gammFit$gam, pages=1)

# Compare ACF residuals to gamm without AR1 -- oddly not a huge difference
gammFitNoAR1 <- gamm(n_articles ~ s(year, by = Dataset)+Dataset,
                family = poisson(link = "log"),
                data=by_dataset3 %>% filter(Dataset != "WOS") %>% droplevels())

opar <- par(mfrow = c(2,2))
acf(residuals(gammFit$gam),main="raw residual ACF")
acf(residuals(gammFit$lme,type="normalized"),main="standardized residual ACF")
acf(residuals(gammFitNoAR1$gam),main="AR1 exclude - raw residual ACF")
acf(residuals(gammFitNoAR1$lme,type="normalized"),main="AR1 exclude - standardized residual ACF")
par(opar)

# Write model summary
sink(here::here("outputs/gammOROBranchTemporalTrendModelSummary.txt"))
print(summary(gammFit$gam))
sink()





# Plot model fits
library(tidymv)

interannualTrendText <- trendCoeff %>% 
  select(Dataset, Value_abs) %>%
  mutate(Value_abs = formatC(Value_abs, digits = 3))
interannualTrendText$Value_abs_label <- paste0("~e^{",interannualTrendText$Value_abs,"}")
interannualTrendText$year <- rep(2020, 4)
interannualTrendText <- interannualTrendText %>%
  inner_join(by_dataset3 %>% 
               filter(Dataset != "WOS" & year == 2020) %>% 
               droplevels() %>% 
               select(Dataset, n_articles),
             by = "Dataset")

  

gamm_ggp <- plot_smooths(model = gammFit$gam, series = year, comparison = Dataset)+
  geom_point(data = by_dataset3 %>% filter(Dataset != "WOS" & 1980 <= year) %>% droplevels(),
             aes(x=year, y = log(n_articles), col = Dataset), size = 0.5, alpha = 0.5)+
  labs(y = "log(N articles)", x= "Year", caption = "All smoothing terms significant, shown on link scale\n Each line labelled with linear trend (1980 - 2022) quantified using gls model of the form:\nlog(N articles) ~ year * Dataset with correlation = corAR1(Year|Dataset)")+
  geom_text(label = "N articles ~ s(Year, by = Dataset) + Dataset\nFamily = poisson(link = 'log')\nCorrelation = corAR1(Year | Dataset)",
            x = 1980, y=12, vjust = 'inward', hjust = 'inward', size = 3)+
  geom_text(data = interannualTrendText %>%
              filter(Dataset != "Societal adaptation"), 
            aes(x=year, y=log(n_articles), label = Value_abs_label),
            parse=TRUE, vjust = -0.5)+
  geom_text(data = interannualTrendText %>%
              filter(Dataset == "Societal adaptation"), 
            aes(x=year, y=log(n_articles), label = Value_abs_label),
            parse=TRUE, vjust = 1.2)+
  xlim(c(1980, 2022))+ ylim(c(0, 12))+
  scale_color_manual(values = c("Scopus"="black", "Mitigation"=varAES$colour[1],
                                "Natural resilience" = varAES$colour[2],
                                "Societal adaptation" = varAES$colour[3]),
                     name = "Dataset",
                     guide=guide_legend(order=2, nrow=2), position = "bottom")+
  scale_fill_manual(values = c("Scopus"="black", "Mitigation"=varAES$colour[1],
                                "Natural resilience" = varAES$colour[2],
                                "Societal adaptation" = varAES$colour[3]),
                     name = "Dataset", guide=guide_legend(order=2, nrow=2), position = "bottom")+
  scale_linetype(name = "Dataset", guide=guide_legend(order=2, nrow=2), position = "bottom")+
  theme_bw()+
  theme(
    legend.position = "bottom"
  )
gamm_ggp


## Save supplemental figure
ggsave(filename = "oroBranchTimeSeriesModelFits.pdf",
       path = here::here("figures/supplemental"), device = 'pdf',
       plot = gamm_ggp, width = 5, height = 5, units = 'in')

```

```{r Supplement - For mitigation quantify the breaking point in the trend}

# Get data frame
mitigationDf <- by_dataset3 %>%
   filter(Dataset == "Mitigation" & 1980 <= year) %>%
   droplevels()

# Fit a spline to get a function that estimates the time series
xl <- seq(1980, 2022, length.out = 100)
f<- splinefun(mitigationDf$year,log(mitigationDf$n_articles))
year_est <- f(xl)

with(mitigationDf, plot(year, log(n_articles),type="l"))
lines(xl, year_est,   col = 'blue')

# Plot derivative -- where it spikes is there is a big inflection in the yearly publication rate
d_est <- f(xl, deriv = 1)
plot(xl, d_est, type = 'l')
xl[which.max(d_est)]


## Format for a nice ggplot
panelADf <- rbind(
  data.frame(year = mitigationDf$year, log_articles = log(mitigationDf$n_articles),
             Dataset = paste("raw data")),
  data.frame(year=xl, log_articles=year_est, Dataset = paste("spline function"))
)

inflect_A_ggp <- ggplot(data = panelADf, aes(year, log_articles, col= Dataset))+
  geom_line(linewidth=1, alpha=0.5)+
  labs(y="log(N articles)", x="Year")+
  scale_colour_manual(values = c("raw data"="black","spline function"="red"))+
  theme_bw()+
  theme(
    legend.position = "bottom"
  )
inflect_A_ggp


panelBDf <- data.frame(year = xl, derivative_est = d_est)
inflect_B_ggp <- ggplot(data=panelBDf, aes(year, derivative_est))+
  geom_line(col="blue")+
  geom_text(x=xl[which.max(d_est)], y=d_est[which.max(d_est)], label = formatC(xl[which.max(d_est)]),
            vjust = 'outward')+
  labs(y="1st derivative", x="Year")+
  theme_bw()

inflect_B_ggp

# Combine panels
require(cowplot)
inflect_ggp <- plot_grid(inflect_A_ggp, inflect_B_ggp, labels = c("a.","b."), align = 'h',
                         axis = 'b')
inflect_ggp

## Save as supplementary file
ggsave(filename = "mitigationBranchInflectionYear.pdf",
       path = here::here("figures/supplemental"), device = 'pdf',
       plot = inflect_ggp, width = 7, height = 4.5, units = 'in')



## What is the trend before and after the inflection?
mitigationDf_gls <- mitigationDf %>%
  mutate(log_articles = log(n_articles)) %>%
  filter(is.finite(log_articles))
# Before 2002
before_fit <- gls(log_articles ~ year, data = mitigationDf_gls %>% filter(year <= 2002), correlation=corAR1())
summary(before_fit)
# After 2002
after_fit <- gls(log_articles ~ year, data = mitigationDf_gls %>% filter(2002 <= year), correlation=corAR1())
summary(after_fit)

exp(after_fit$coefficients)

# Export model summaries
sink(here::here("outputs/glsMitigationBeforeAndAfterInflectionModelSummary.txt"))
print("BEFORE 2002 -------------")
print(summary(before_fit))
print("AFTER 2002 -------------")
print(summary(after_fit))
sink()

```



```{r Supplement - When to the breaking points in the trends occur for all branches?}

# Get data frame
allBranchDf <- by_dataset3 %>%
   filter(Dataset %in% c("Mitigation","Natural resilience",
                         "Societal adaptation") & 1980 <= year) %>%
   droplevels()

# Fit a spline to get a function that estimates the time series
xl <- seq(1980, 2022, length.out = 100) # the years to estimate over

# Funciton to fit the model
spline_fit <- function(dat){
  y = log(dat$n_articles)
  x = dat$year[is.finite(y)]
  y = y[is.finite(y)]
  splinefun(x,y)
}
splineFits <- lapply(split(allBranchDf, allBranchDf$Dataset), spline_fit)
splinePredictions <- lapply(splineFits, function(f) f(xl))
splineDerivatives <- lapply(splineFits, function(f) f(xl, deriv=1))


## Format for a nice ggplot
panelADf <- rbind(
  data.frame(year = allBranchDf$year, log_articles = log(allBranchDf$n_articles),
             Dataset = paste("raw data"), ORO_branch = allBranchDf$Dataset),
  data.frame(year=rep(xl, 3), log_articles=unlist(splinePredictions), 
             ORO_branch = c(rep("Mitigation",100), rep("Natural resilience", 100),
                            rep("Societal adaptation",100)),
             Dataset = paste("spline function"))
)

inflect_A_ggp <- ggplot(data = panelADf %>% filter(is.finite(log_articles)), 
                        aes(year, log_articles, col= Dataset))+
  facet_grid(.~ORO_branch)+
  geom_line(linewidth=1, alpha=0.5)+
  labs(y="log(N articles)", x="Year")+
  ylim(c(0, max(panelADf$log_articles, na.rm=T)))+
  scale_colour_manual(values = c("raw data"="black","spline function"="red"))+
  theme_bw()+
  theme(
    legend.position = "top"
  )
inflect_A_ggp


panelBDf <- data.frame(year = rep(xl, 3), derivative_est = unlist(splineDerivatives),
                       ORO_branch = c(rep("Mitigation",100), rep("Natural resilience", 100),
                            rep("Societal adaptation",100)))

# Select the outliers
panelBText <- panelBDf %>%
  group_by(ORO_branch) %>%
  mutate(isOutlier = rstatix::is_outlier(derivative_est, coef = 1.5)) %>%
  filter(isOutlier & 0 < derivative_est) %>%
  mutate(year = as.integer(year))%>%
  group_by(year, ORO_branch) %>%
  slice(which.max(derivative_est)) %>%
  filter(1981 < year)


inflect_B_ggp <- ggplot(data=panelBDf, aes(year, derivative_est))+
  facet_grid(.~ORO_branch)+
  geom_line(col="blue")+
  geom_text(data= panelBText, aes(year, derivative_est, label = formatC(year)), 
            vjust = -0.2, hjust = -0.2)+
  xlim(c(1981,2022))+
  labs(y="1st derivative", x="Year")+
  theme_bw()

inflect_B_ggp

# Combine panels
require(cowplot)
inflect_ggp <- plot_grid(inflect_A_ggp, inflect_B_ggp, labels = c("a.","b."), align = 'v',
                         nrow=2)
inflect_ggp

## Save as supplementary file
ggsave(filename = "allBranchInflectionYear.pdf",
       path = here::here("figures/supplemental"), device = 'pdf',
       plot = inflect_ggp, width = 7, height = 6, units = 'in')
```


```{r Supplement - temporal evolution of mitigation vs adaptation ratio}

## Create a dataset for the mitigation vs adaptation ratio for each year
mit_vs_adapt_yr <- by_dataset3 %>%
  filter(Dataset %in% c("Mitigation","Natural resilience","Societal adaptation")) 
mit_vs_adapt_yr <- reshape2::dcast(mit_vs_adapt_yr, formula = year ~ Dataset, fill = 0, value.var = "n_articles")
mit_vs_adapt_yr <- mit_vs_adapt_yr %>%
  mutate(Adaptation = `Natural resilience` + `Societal adaptation`) %>%
  dplyr::select(year, Mitigation, Adaptation) 
mit_vs_adapt_yr <- mit_vs_adapt_yr %>%
  mutate(total_n = Mitigation + Adaptation) %>%
  mutate(prop_mit = Mitigation/total_n,
         prop_adapt = Adaptation/total_n) %>%
  filter(is.finite(prop_mit) & is.finite(prop_adapt)) %>%
  #filter(quantile(total_n, probs = 0.1) < total_n) %>%
  na.omit()

summary(mit_vs_adapt_yr)

ggplot()+
  geom_point(data =mit_vs_adapt_yr, aes(year, prop_mit), col = "blue")+
  geom_point(data =mit_vs_adapt_yr, aes(year, prop_adapt), col = "purple")

# Fit a logistic regression and plot predictions
fit <- glm(cbind(Adaptation, Mitigation) ~ year, family = binomial, data = mit_vs_adapt_yr)
summary(fit)

d_new <- data.frame(year = seq(min(mit_vs_adapt_yr$year), max(mit_vs_adapt_yr$year), length.out = 100))
pred_dat <- predict(fit, d_new, type = 'response', se.fit = TRUE)
d_new$mean <- pred_dat$fit
d_new$se <- pred_dat$se.fit

ggplot()+
  geom_line(data = d_new, aes(year, mean)) + 
  geom_ribbon(data = d_new, aes(year, ymin = mean-se, ymax = mean+se), alpha = 0.5, fill = "pink")+
  geom_point(data =mit_vs_adapt_yr, aes(year, prop_adapt), col = "purple")+
  ylim(c(0,0.25))


# Durbin Watson test to check if we need AR1 correlation -- yes, so model a gamm smooth and test if s(year) is still significant -- it is
require(glmmTMB)
require(DHARMa)
require(multcomp)
require(Rfast)

testar <- function(mod, dat) { # function to test ar
  simres <- simulateResiduals(mod,plot=T)
  res <-  recalculateResiduals(simres, group = dat$year)
  print(testTemporalAutocorrelation(res, time=unique(dat$year)))

}
mod.TMB <- glmmTMB(cbind(Adaptation, Mitigation) ~  year, family = "betabinomial", data=mit_vs_adapt_yr)
testar(mod.TMB, mit_vs_adapt_yr) # So we reject the null hypothesis (p = 0.007) -- autocorrelation is present

fit_corAR1 <- gamm(cbind(Adaptation, Mitigation) ~ s(year),correlation=corAR1(),data=mit_vs_adapt_yr, family = binomial('logit'))
summary(fit_corAR1$gam) 
# Approximate significance of smooth terms:
#          edf Ref.df     F p-value    
# s(year) 5.22   5.22 125.5  <2e-16 ***



# Add predictions of gamm to plot
predGam <- predict(fit_corAR1$gam, data.frame(year = d_new$year), type = "response", se.fit = TRUE)
d_new$mean_gam <- predGam$fit
d_new$se_gam <- predGam$se.fit

# Text summaries of model results
# Odds ratio = number of adaptation/number of mitigation
interpretationText <- paste("The logistic glm indicates the odds of publishing on an adaptation ORO (vs mitigation) changes by", signif(exp(coefficients(fit)[2]), 2), "per year (p < 2e-16), which amounts to a", (signif(exp(coefficients(fit)[2]), 2)-1)*100,"% annual increase")
#print(interpretationText)



mit_vs_adapt_annual_ggp <- ggplot()+
  # plot glm fit
  geom_line(data = d_new, aes(year, mean), col = "red") + 
  geom_ribbon(data = d_new, aes(year, ymin = mean-se, ymax = mean+se), alpha = 0.5, fill = "pink")+
  
  # plot gamm fit
  geom_line(data = d_new, aes(year, mean_gam), col = "blue") + 
  geom_ribbon(data = d_new, aes(year, ymin = mean_gam-se_gam, ymax = mean_gam+se_gam), alpha = 0.5, fill = "blue")+
  geom_point(data =mit_vs_adapt_yr, aes(year, prop_adapt), col = "purple")+
  
  # Plot glm summary text
  labs(#caption = paste0(strwrap(interpretationText, width = 0.7 * getOption("width")), collapse="\n"),
       y = "Proportion of adaptation publications", x = "Year")+
  
  # label lines
  geom_text(data = data.frame(x=c(1975, 2000), y=c(0.05, 0.05),labels = c("GLM","GAM")),
            aes(x,y, label = labels, col = labels))+
  scale_color_manual(values = c("GLM" = "red", "GAM" = "blue"), guide = "none")+
  
  # format legend
  # Format scales
  scale_fill_manual()+
  
  ylim(c(0,0.25))+
  theme_bw()+
  theme(
    legend.position = "bottom"
  )


## Save as supplementary file
ggsave(filename = "mitigation_vs_adaptation_ratio_annual.pdf",
       path = here::here("figures/supplemental"), device = 'pdf',
       plot = mit_vs_adapt_annual_ggp, width = 5, height = 4, units = 'in')

```



# Panel B: Barplot of N articles for each ORO type, filled by % articles in IPCC report. Perhaps also label at the top of the bar the year of the inflexion point of the exponential relationship

```{r load predictions for ORO type}
predRel <- tbl(dbcon, "pred_relevance") 
predType <- tbl(dbcon, "pred_oro_type_long") 
uniquerefs <- tbl(dbcon, "uniquerefs")

## Format and collect needed data
predTypeDf <- predRel %>%
  filter(thresholdLevel <= relevance_mean) %>%
  select(analysis_id) %>%
  inner_join(predType, by ="analysis_id") %>%
  collect()

predTypeRefs <- predType %>%
  left_join(uniquerefs %>% select(analysis_id, year, title, doi, source_title), by="analysis_id")%>%
  collect()

uniquerefs <- uniquerefs %>% collect()
```

```{r check method to flag if a source is a conference proceeding, eval = FALSE}
# First check that just a search for the word conference in the source title returns sensible results
sources <- unique(predTypeRefs$source_title)
conf_match <- sources[grep("conference", sources, ignore.case=TRUE)]
conf_match[1:50] # check that this makes sense -- yes

```


```{r Sum number of relevant articles for each oro type and boundary}
#factor_aes <- readxl::read_excel(here::here("R/factor_aesthetics.xlsx"))


oroTypeSums <- predTypeDf %>% 
  left_join(uniquerefs %>% select(analysis_id, year, title, doi, source_title), by="analysis_id")%>% 
  mutate(conference_proceeding = grepl("conference", source_title, ignore.case=TRUE)) %>%
  group_by(oro_type, conference_proceeding) %>%
  summarise(
    n_mean = sum(thresholdLevel <= mean)
    # n_lower = sum(thresholdLevel <= lower),
    # n_upper = sum(thresholdLevel <= upper)
  ) 
oroTypeSums

oroTypeSums_confidence <- predTypeDf %>% 
  group_by(oro_type) %>%
  summarise(
    n_mean = sum(thresholdLevel <= mean),
    n_lower = sum(thresholdLevel <= lower),
    n_upper = sum(thresholdLevel <= upper)
  ) 
oroTypeSums_confidence

## Format data for plotting by factoring using common aesthetics

# Read in the aethetics for oro_type -- determines order of x axis
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
oroTypeSums$oro_type <- factor(
  oroTypeSums$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)
oroTypeSums_confidence$oro_type <- factor(
  oroTypeSums_confidence$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Join in with aesthetics for ORO branch -- determines colour of bar by oro_branch
branchAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
branchTypeLookup <- data.frame(
  label = typeAES$label,
  oro_branch = c(rep("Mitigation",3), rep("Natural resilience",2), rep("Societal adaptation",2))
)
typeAES <- merge(typeAES, branchTypeLookup,
                 by = "label") %>%
  rename(oro_type = label)


# Merge sums with plotting order, colour and corresponding branch 
oroTypeSums <- merge(oroTypeSums,typeAES[,c("oro_type","order","colour","oro_branch")])
oroTypeSums$oro_branch <- factor(oroTypeSums$oro_branch,
                                 levels = branchAES$label[branchAES$order])
oroTypeSums$order <- factor(oroTypeSums$order,
                            levels = oroTypeSums$order[order(oroTypeSums$order)])

oroTypeSums_confidence <- merge(oroTypeSums_confidence,typeAES[,c("oro_type","order","colour","oro_branch")])
oroTypeSums_confidence$oro_branch <- factor(oroTypeSums_confidence$oro_branch,
                                 levels = branchAES$label[branchAES$order])
oroTypeSums_confidence$order <- factor(oroTypeSums_confidence$order,
                            levels = oroTypeSums_confidence$order[order(oroTypeSums_confidence$order)])

```

NB the chunk below takes long to run so comment out and load output in next chunk
```{r read in IPCC AR6 bibliographies, eval = FALSE}
# # Read in files as data frames
# bibDir <- here::here("data/external/IPCC-AR6-bibtex-files")
# ipccBib <- rbibtools::read_bib(bibDir, tags = c("year","title","doi"))
# 
# # deduplicate based on year, and defaults to doi followed by title when match_variable is blank
# unique_id = revtools::find_duplicates(data = ipccBib,
#                             group_variables = "year",
#                             match_function = "stringdist", 
#                             method = "osa", threshold = 5,
#                             remove_punctuation = TRUE, to_lower = TRUE)
# length(unique_id) # number of articles = 82438
# sum(duplicated(unique_id)) # number of duplicates = 52445
# # therefore 64 % of articles are duplicates
# 
# ipccBibUnique <- revtools::extract_unique_references(
#   ipccBib, unique_id
# )
# 
# # Assign a bib ID to each unique article
# ipccBibUnique$ipccRef_id <- paste0("ipcc_",seq(1, nrow(ipccBibUnique)))
# 
# # Save
# save(ipccBibUnique,file = file.path(bibDir, "IPCC_AR6_uniquerefs.RData"))

```

NEXT STEP: identify matches between ipcc refs and our database.

See file 'Figure1_ipccTitleMatching_rossi.R' as this was run on the server. Results file is located at the following relative path: 'data/external/IPCC-AR6-bibtex-files/IPCC_AR6_uniquerefs_matches.RData'
```{r clean dataframe on ipcc matches}
# Load in de-deuplicated ipcc matches
load(here::here('data/external/IPCC-AR6-bibtex-files/IPCC_AR6_uniquerefs_matches.RData'))
ipccRefsTotal <- nrow(ipccMatches)
# Filter to only records where there is a match for an analysis_id
ipccMatches <- ipccMatches[!is.na(ipccMatches$ipccRef_id),]


# ## Load and check that matches make sense
# load(here::here("data/external/IPCC-AR6-bibtex-files/IPCC_AR6_uniquerefs.RData"))
# 
# ipccMatches %>% 
#   select(title, ipccRef_id) %>%
#   head() %>%
#   left_join(ipccBibUnique %>% select(title, ipccRef_id), by= "ipccRef_id")

```

```{r using the title matches sum the number and percentage of matches found in ipcc}

# For each ORO, sum the number of matches to the ipcc
oroMatchesSums <- predTypeDf %>%
  inner_join(ipccMatches, by="analysis_id") %>%
  group_by(oro_type) %>%
  summarise(
    n_mean = sum(thresholdLevel <= mean),
    n_lower = sum(thresholdLevel <= lower),
    n_upper = sum(thresholdLevel <= upper), 
    .drop = FALSE
  ) 


## Format data for plotting by factoring using common aesthetics

# Read in the aethetics for oro_type -- determines order of x axis
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# factor oro_type column
oroMatchesSums$oro_type <- factor(
  oroMatchesSums$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Join in with aesthetics for ORO branch -- determines colour of bar by oro_branch
branchAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
# typeAES <- merge(typeAES, branchAES[,c("label","colour")] %>%rename(oro_branch = label), 
#                  by = "colour") %>%
#   rename(oro_type = label)
branchTypeLookup <- data.frame(
  label = typeAES$label,
  oro_branch = c(rep("Mitigation",3), rep("Natural resilience",2), rep("Societal adaptation",2))
)
typeAES <- merge(typeAES, branchTypeLookup,
                 by = "label") %>%
  rename(oro_type = label)

# Merge sums with plotting order, colour and corresponding branch 
oroMatchesSums <- merge(oroMatchesSums,typeAES[,c("oro_type","order","colour","oro_branch")])
oroMatchesSums$oro_branch <- factor(oroMatchesSums$oro_branch,
                                 levels = branchAES$label[branchAES$order])
oroMatchesSums$order <- factor(oroMatchesSums$order,
                            levels = oroMatchesSums$order[order(oroMatchesSums$order)])


## Lastly calculate sums as a proportion of total corpus of each oro type
oroMatchesProp <- merge(oroMatchesSums, oroTypeSums, 
                        by = c("oro_type","order","colour","oro_branch"),
                        suffixes = c(".matches",".total"))
oroMatchesProp <- oroMatchesProp %>%
  mutate(
    prop_mean = n_mean.matches/n_mean.total,
    prop_lower = n_lower.matches/n_lower.total,
    prop_upper = n_upper.matches/n_upper.total
  )

## What is the percentage of IPCC literature dedicated to a particular ORO?

oroMatchesProp_IPCC <- oroMatchesSums %>%
  mutate(prop_IPCC = n_mean/ipccRefsTotal,
         prop_IPCC_ORO = n_mean/sum(oroMatchesSums$n_mean, na.rm=T)) %>%
  select(oro_type, prop_IPCC,prop_IPCC_ORO, order, colour, oro_branch)

oroMatchesProp_IPCC <- rbind( # add in a row for other topics
  oroMatchesProp_IPCC %>%
    mutate(order = as.numeric(order)),
  data.frame(
    oro_type = "Non-ORO",
    prop_IPCC = 1-sum(oroMatchesProp_IPCC$prop_IPCC),
    prop_IPCC_ORO = 1-sum(oroMatchesProp_IPCC$prop_IPCC_ORO),
    order = nlevels(oroMatchesProp_IPCC$order)+1,
    colour = "grey",
    oro_branch = "Non-ORO"
  )
)

```



```{r plot panel B}
typeLabels <- merge(factor_aes[which(factor_aes$variable == "oro_type"),],
                      modelScores[grep("oro_any", modelScores$model),] %>% 
                      select(`label name`, `F1 - label`) %>%
                      mutate(`label name` = ifelse(
                        grepl("Renewable", `label name`), "Marine renewable energy", ifelse(
                          grepl("CO2", `label name`), "CO2 removal or storage", ifelse(
                            grepl("Increase", `label name`),"Increase efficiency", ifelse(
                              grepl("Human", `label name`),"Human assisted evolution", ifelse(
                              grepl("Conservation", `label name`),"Conservation", ifelse(
                                grepl("Built", `label name`),"Built infrastructure & technology", ifelse(
                                  grepl("Socio", `label name`),"Socio-institutional", NA
                                )
                              )
                            )
                          )
                        )
                      ))) %>%
                      na.omit(),
                      by.x = "level", by.y = "label name")%>%
  mutate(branchLabelF1 = paste0(label,", F1 = ", signif(`F1 - label`, 2)))
typeLabels <- typeLabels[order(typeLabels$order),]

fig1_B_ggp <- ggplot()+
  # plot bars number of model predictions
  geom_col(data=oroTypeSums, aes(x=order, y=n_mean, fill = oro_type, alpha = conference_proceeding), position="stack")+
  geom_errorbar(data=oroTypeSums_confidence, aes(x=order, ymin = n_lower, ymax = n_upper), width=.2)+
  geom_text(data=oroTypeSums_confidence, aes(x=order, y=n_upper,label = n_mean), nudge_y = 1500, size=3, col="black")+ #nudge_x=0.2,
  
  # # Add text for percent found in ipcc citations
  # geom_text(data = oroMatchesProp,
  #           aes(x=order, y=n_upper.total, label = paste(signif(prop_mean*100, 2),"%")), 
  #           size=3, col="black", nudge_y = 3500)+ 
  
  # Add text to indicate conference proceeding
  geom_text(data = data.frame(x=1,
                              y=oroTypeSums$n_mean[
                                which(oroTypeSums$oro_type == "Marine renewable energy" & 
                                        oroTypeSums$conference_proceeding == TRUE)]/2,
                              label = "conference\nproceeding"),
            aes(x=x,y=y,label=label), size = 2, col="black", inherit.aes = FALSE)+
  
 
  # Format scales
  scale_fill_manual(name = "ORO\ntype", 
                    values = as.vector(typeAES$colour[order(typeAES$order)]),
                    labels = typeLabels$branchLabelF1, ## this adds F1 to label
                    guide = guide_legend(ncol=2))+
  scale_alpha_manual(values = c("TRUE" = 0.6, "FALSE"=1), guide = "none")+
  scale_x_discrete(limits = levels(oroTypeSums$order), 
                    labels = levels(oroTypeSums$oro_type))+
  
  labs(y="N articles")+
  theme(
    panel.background = element_rect(fill="white",colour = "black"),
    panel.grid.major = element_line(colour = "grey"),
    axis.text.y = element_text(size=8),
    axis.text.x = element_text(angle=45, hjust=1, size=8),
    axis.title.x = element_blank(),
    legend.text = element_text(size=7),
    legend.title = element_text(size=10),
    legend.position = "bottom",
    legend.key.size = unit(0.3, "cm"),
    plot.margin = margin(0.1,0.5,0.1,0.1, unit="cm")
  )

fig1_B_ggp


## Doughnut plot of the proportion of IPCC literature devoted to each oro type

prop_IPCC <- oroMatchesProp_IPCC %>%
  arrange(oro_type) %>%
  mutate(ymax = cumsum(prop_IPCC)) %>% 
  mutate(ymax = ifelse(oro_type == "Non-ORO", 1, ymax),
         ymin = lag(ymax, default = 0))
all_ORO_in_IPCC <- 1-prop_IPCC$prop_IPCC[which(prop_IPCC$oro_type == "Non-ORO")]
all_ORO_in_IPCC <- paste0(signif(all_ORO_in_IPCC, digits = 2)*100,"%", collapse=" ")

prop_IPCC_ORO <- oroMatchesProp_IPCC %>%
  arrange(oro_type) %>%
  mutate(ymax = cumsum(prop_IPCC_ORO)) %>% 
  mutate(ymax = ifelse(oro_type == "Non-ORO", 1, ymax),
         ymin = lag(ymax, default = 0))

fig1_B_doughnut_ggp <- 
  ggplot()+
  #geom_rect(data = prop_IPCC, aes(ymax = ymax, ymin = ymin, xmax = 3, xmin = 2, fill = oro_type))+
  geom_rect(data = prop_IPCC_ORO, aes(ymax = ymax, ymin = ymin, xmax = 4, xmin = 2.5, fill = oro_type))+
  geom_text(data = data.frame(x=0,y=0,label = all_ORO_in_IPCC),
            aes(x,y,label=label), size = 4.5)+
  xlim(c(0,4))+
  coord_polar(theta = "y")+
  scale_fill_manual(name = "",values = as.vector(oroMatchesProp_IPCC$colour[order(oroMatchesProp_IPCC$order)]),
                    breaks = as.vector(oroMatchesProp_IPCC$oro_type[oroMatchesProp_IPCC$order]))+
  ggtitle("IPCC")+
  # scale_x_discrete(limits = levels(typeMethodDf$order), 
  #                   labels = levels(typeMethodDf$oro_type))+
  # ylim(c(0,105))+
  # guides(fill=guide_legend(ncol=2))+
  
  # labs(y="Percent contribution")+
  theme(
    panel.background = element_rect(fill = "transparent",colour = NA), # or theme_blank()
    panel.grid.minor = element_blank(), 
    panel.grid.major = element_blank(),
    plot.background = element_rect(fill = "transparent",colour = NA),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    strip.background = element_blank(),
    strip.text = element_blank(),
    legend.position = "none",
    plot.title = element_text(hjust = 0.5, vjust = 0)
  )
fig1_B_doughnut_ggp

require(cowplot)

fig1_B_ggp_inset <- ggdraw()+
  draw_plot(fig1_B_ggp)+
  draw_plot(fig1_B_doughnut_ggp,x=0.63,y=0.65, height=0.35, width = 0.35)
fig1_B_ggp_inset
```


# Add venn diagram of interactions between ORO branches

```{r calculate interactions between branches}

predBranch <- tbl(dbcon, "pred_oro_branch") 

## Join together to get relevance preditions for all included
oroBranchInteractions <- predBranch %>% 
  select(analysis_id, `oro_branch.Mitigation - mean_prediction`, `oro_branch.Nature - mean_prediction`,
         `oro_branch.Societal - mean_prediction`) %>%
  rename(Mitigation = `oro_branch.Mitigation - mean_prediction`, 
         `Natural resilience` = `oro_branch.Nature - mean_prediction`,
         `Societal adaptation` = `oro_branch.Societal - mean_prediction`) %>%
  mutate(Mitigation = ifelse(thresholdLevel <= Mitigation, 1,0),
         `Natural resilience` = ifelse(thresholdLevel <= `Natural resilience`, 1,0),
         `Societal adaptation` = ifelse(thresholdLevel <= `Societal adaptation`, 1,0)) %>%
  collect()

oroBranchInteractions %>%
  filter(Mitigation == 1 ) %>%
  nrow


devtools::install_github("gaospecial/ggVennDiagram")
require(ggVennDiagram)
oroBranchInteractions_venn <- list(
  oroBranchInteractions$analysis_id[oroBranchInteractions$Mitigation == 1],
  oroBranchInteractions$analysis_id[oroBranchInteractions$`Natural resilience` == 1],
  oroBranchInteractions$analysis_id[oroBranchInteractions$`Societal adaptation` == 1]
)
names(oroBranchInteractions_venn) <- c(colnames(oroBranchInteractions)[2:4])
ggVennDiagram(oroBranchInteractions_venn)

# # Format aesthetics for plotting
branchAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
branchAES <- branchAES[order(branchAES$order),]
# 
# oroBranchInteractions <- oroBranchInteractions %>%
#   mutate(oro_type = factor(oro_type, levels = typeAES$level, labels = typeAES$label))
# 
# # format as tabular data
# oroTypeDf_wide <- oroTypeDf %>%
#   select(analysis_id, oro_type) %>%
#   mutate(count = 1) %>%
#   reshape2::dcast(analysis_id ~ oro_type, drop=FALSE, value.var = "count")

upsetCols <- typeAES %>%
  rename(set = label, fill = colour) %>%
  select(set, fill)


# Also calculate interaction matrix
oroTypeDf_mat <- crossprod(table(oroTypeDf[,c("analysis_id","oro_type")]))

```


```{r plot the venn diagram of overlap between branches}
predRel <- tbl(dbcon, "pred_relevance") %>%
  filter(0.5 <= relevance_mean) %>%
  select(analysis_id)
predBranch <- tbl(dbcon, "pred_oro_type_long") %>%
  filter(0.5 <= mean) %>%
  select(analysis_id, oro_branch)

## Join together to get relevance preditions for all included
oroBranchDf <- predRel %>%
  inner_join(predBranch, by ="analysis_id") %>% 
  select(analysis_id, oro_branch) %>%
  collect()
# remove branch duplicates
oroBranchDf <- oroBranchDf[!duplicated(oroBranchDf),]

oroBranchInteractions_venn <- list(
  oroBranchDf$analysis_id[oroBranchDf$oro_branch == "Mitigation"],
  oroBranchDf$analysis_id[oroBranchDf$oro_branch == "Natural resilience"],
  oroBranchDf$analysis_id[oroBranchDf$oro_branch == "Societal adaptation"]
)
names(oroBranchInteractions_venn) <- c("Mitigation","Natural resilience","Societal adaptation")

# Get aesthetics

branchAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
branchAES <- branchAES[order(branchAES$order),]

# Plot
require(ggvenn)
interactions_venn_ggp <- ggvenn(oroBranchInteractions_venn,
       show_percentage = FALSE,
       fill_color = branchAES$colour, fill_alpha = 1,
       text_color = "white",
       stroke_size = 0.5, set_name_size = 4)



```


# Assemble Panels and write figure

```{r assemble panels and write figure}
# pdf(here::here("figures/main/oroBranchTimeAndIpccMatches.pdf"),
#     width = 8, height=4.5)
# egg::ggarrange(fig1_A_ggp+theme(legend.position = "bottom"), fig1_B_ggp+theme(legend.position = "bottom"),
#           nrow=1, ncol=2, newpage = FALSE, labels = c("a.","b."))
# dev.off()

fig1_ggp <- plot_grid(fig1_B_ggp_inset+theme(legend.position = "bottom", 
                                       plot.margin = margin(0.1,0.8,0.1,0.1, unit="cm")),
                      fig1_A_ggp+theme(legend.position = "bottom"),
          nrow=1, ncol=2, labels = c("a.","b."), align = "v", axis="b", rel_widths = c(1.3,1))

ggsave(filename = "oroBranchTimeAndIpccMatches.pdf",
       path = here::here("figures/main"), device = 'pdf',
       plot = fig1_ggp, width = 8, height = 4.5, units = 'in')

```


```{r version with venn diagram}

require(ggpubr)
panelclegend <- get_legend(fig1_A_ggp+theme(legend.position = "bottom"))
panelclegend <- as_ggplot(panelclegend)


fig1_ggp <- plot_grid(fig1_B_ggp_inset+theme(legend.position = "bottom", 
                                       plot.margin = margin(0.1,0.8,0.1,0.1, unit="cm")),
                      interactions_venn_ggp+theme(plot.margin = margin(0,0,0,0, unit="cm")),
                      fig1_A_ggp+theme(legend.position = "none"),
                      panelclegend,
                      scale = c(1,1.2,1,1),
          nrow=2, ncol=2, labels = c("a.","b.","c",""), align = "hv", axis="b", rel_widths = c(1.3,1),
          rel_heights = c(2,1))


## Save file
ggsave(filename = "oroBranchTimeAndIpccMatches_Venn.pdf",
       path = here::here("figures/main"), device = 'pdf',
       plot = fig1_ggp, width = 9.5, height = 8.5, units = 'in')
```


# Supplementary figure: timeline of mitigation OROs


```{r Sum n articles per mitigation ORO per year}
predRel <- tbl(dbcon, "pred_relevance") 
predType <- tbl(dbcon, "pred_oro_type_long") 
uniquerefs <- tbl(dbcon, "uniquerefs")

## Format and collect needed data
predMitigationDf <- predRel %>%
  filter(thresholdLevel <= relevance_mean) %>%
  select(analysis_id) %>%
  inner_join(predType, by ="analysis_id") %>%
  filter(oro_branch == "Mitigation") %>%
  left_join(uniquerefs %>% select(analysis_id, year), by = "analysis_id") %>%
  collect()



mitigation_oro_by_year_sums <- predMitigationDf %>%
  filter(1980 <= year) %>%
  group_by(oro_type, year) %>%
  summarise(
    mean = sum(thresholdLevel <= mean),
    lower = sum(thresholdLevel <= lower),
    upper = sum(thresholdLevel <= upper)
  ) 


# Factor and format
mitigationAES <- factor_aes[which(factor_aes$level %in% unique(mitigation_oro_by_year_sums$oro_type)),]
mitigationAES$order <- order(mitigationAES$order)
mitigationAES <- mitigationAES[mitigationAES$order,]

mitigation_oro_by_year_sums <- mitigation_oro_by_year_sums%>%
  na.omit() %>%
  mutate(year = as.Date(paste0(year, "-01-01")),
         oro_type = factor(oro_type, levels = mitigationAES$level, labels = mitigationAES$label))


summary(mitigation_oro_by_year_sums)


# text labels
mitigation_oro_text <- mitigation_oro_by_year_sums %>%
  filter(year == as.Date("2020-01-01")) 

```

```{r PLOT timeline of mitigation OROs}

Sfig_mitigation_oro_ggp <- ggplot()+
  geom_ribbon(data = mitigation_oro_by_year_sums, 
              aes(x=year, ymin = log(lower), ymax=log(upper), fill = oro_type), alpha = 0.5)+
  geom_line(data = mitigation_oro_by_year_sums, aes(x=year, y=log(mean), col=oro_type), 
            linewidth = 1,
            na.rm=T)+
  geom_text(data= mitigation_oro_text, 
            aes(x=year, y=log(upper), label = stringr::str_wrap(oro_type, width=30)),
            vjust = "outward", hjust="inward", size=3, col="black")+

  # Format scales
  scale_color_manual(values = mitigationAES$colour, 
                     name = "Mitigation\nORO type", guide=guide_legend(order=1, nrow=1))+
  scale_fill_manual(values = mitigationAES$colour, guide = "none")+
  labs(x="Year", y="log(N articles)")+
  scale_x_date(limits = c(as.Date("1980-01-01"),max(mitigation_oro_by_year_sums$year)))+
  scale_y_continuous(sec.axis = sec_axis(trans = exp, name = "N articles", 
                                         breaks = c(0,100,1000,10000,30000,80000),
                                         labels = function(x) formatC(x, big.mark=",", format="d")),
                     breaks = seq(0,10, by= 2))+
  theme_classic()+
  theme(
    legend.position = "none",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )


Sfig_mitigation_oro_ggp

ggsave(here::here("figures/supplemental/mitigationOROsTimeline.pdf"), width=6, height=4, units="in")
```







# Supplementary figure: Multipanel timeline of all ORO types by branch


```{r Sum n articles per mitigation ORO per year}
predRel <- tbl(dbcon, "pred_relevance") 
predType <- tbl(dbcon, "pred_oro_type_long") 
uniquerefs <- tbl(dbcon, "uniquerefs")

## Format and collect needed data
predTypeDf <- predRel %>%
  filter(thresholdLevel <= relevance_mean) %>%
  select(analysis_id) %>%
  inner_join(predType, by ="analysis_id") %>%
  left_join(uniquerefs %>% select(analysis_id, year), by = "analysis_id") %>%
  collect()



type_oro_by_year_sums <- predTypeDf %>%
  filter(1980 <= year) %>%
  group_by(oro_type, year) %>%
  summarise(
    mean = sum(thresholdLevel <= mean),
    lower = sum(thresholdLevel <= lower),
    upper = sum(thresholdLevel <= upper)
  ) 

# Add branch columb for facetting
source(here::here("R/branchMapFn.R"))
type_oro_by_year_sums$oro_branch <- mapply(branchMapFn, type_oro_by_year_sums$oro_type)


# Factor and format
typeAES <- factor_aes[which(factor_aes$level %in% unique(type_oro_by_year_sums$oro_type)),]
typeAES$order <- order(typeAES$order)
typeAES <- typeAES[typeAES$order,]

branchAES <- factor_aes[which(factor_aes$variable == "ORO_branch"),]
branchAES$order <- order(branchAES$order)
branchAES <- branchAES[branchAES$order,]

type_oro_by_year_sums <- type_oro_by_year_sums%>%
  na.omit() %>%
  mutate(year = as.Date(paste0(year, "-01-01")),
         oro_type = factor(oro_type, levels = typeAES$level, labels = typeAES$label),
         oro_branch = factor(oro_branch, levels = branchAES$label))


summary(type_oro_by_year_sums)


# text labels
type_oro_text <- type_oro_by_year_sums %>%
  filter(year == as.Date("2020-01-01")) 

type_oro_text$upper[which(type_oro_text$oro_type == "Socio-institutional")] <- 100

```

```{r PLOT timeline of all OROs}

Sfig_oro_ggp <- ggplot()+
  facet_grid(oro_branch~.)+
  geom_ribbon(data = type_oro_by_year_sums, 
              aes(x=year, ymin = log(lower), ymax=log(upper), fill = oro_type), alpha = 0.5)+
  geom_line(data = type_oro_by_year_sums, aes(x=year, y=log(mean), col=oro_type), 
            linewidth = 1,
            na.rm=T)+
  geom_text(data= type_oro_text, 
            aes(x=year, y=log(upper), label = stringr::str_wrap(oro_type, width=50)),
            vjust = "outward", hjust="inward", size=3, col="black")+

  # Format scales
  scale_color_manual(values = typeAES$colour, 
                     name = "ORO type", guide=guide_legend(order=1, nrow=1))+
  scale_fill_manual(values = typeAES$colour, guide = "none")+
  labs(x="Year", y="log(N articles)")+
  scale_x_date(limits = c(as.Date("1980-01-01"),as.Date("2022-12-31")))+
  scale_y_continuous(sec.axis = sec_axis(trans = exp, name = "N articles", 
                                         #breaks = c(0,100,1000,10000,30000,80000),
                                         labels = function(x) formatC(x, big.mark=",", format="d")),
                     breaks = seq(0,10, by= 2))+
  theme_classic()+
  theme(
    legend.position = "none",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )


Sfig_oro_ggp

ggsave(here::here("figures/supplemental/allOROsTimeline.pdf"), width=5, height=6, units="in")
```




# Supplementary figure: Sensitivity analysis of relative distribution across ORO types over changing screening relevance threshold

Question: As the relevance threshold changes, does the relative distribution stay the same between the ORO types?

```{r load and format data}
## Load data to get ORO type and relevance for each article
predRel <- tbl(dbcon, "pred_relevance") 
predType <- tbl(dbcon, "pred_oro_type_long") 

thresholdSensitivityDf <- predRel %>%
  select(analysis_id, relevance_mean) %>%
  inner_join(predType, by ="analysis_id") %>%
  collect()

```

```{r To see if the distribution changes over different relevance values Across different threshold windows, calculate the proportion of articles for each ORO}

thresholdBreaks <- seq(0.5,1, by=0.1)

for(b in 1:(length(thresholdBreaks)-1)){
  
  if(b == 1){
    tempDat <- thresholdSensitivityDf %>%
      filter(thresholdBreaks[b] <= relevance_mean & relevance_mean <= thresholdBreaks[b+1]) %>%
      group_by(oro_type) %>%
      summarise(
        n = sum(0.5 <= mean)
        ) %>%
      mutate(threshold = paste0(thresholdBreaks[b], "-", thresholdBreaks[b+1]),
             threshold_order = b)
  }else{
    tempDat <- thresholdSensitivityDf %>%
      filter(thresholdBreaks[b] < relevance_mean & relevance_mean <= thresholdBreaks[b+1]) %>%
      group_by(oro_type) %>%
      summarise(
        n = sum(0.5 <= mean)
        ) %>%
      mutate(threshold = paste0(thresholdBreaks[b], "-", thresholdBreaks[b+1]),
             threshold_order = b)
  }
  
  if(b==1){
    thresholdSumsDf <- tempDat
  }else{
    thresholdSumsDf <- rbind(thresholdSumsDf, tempDat)
  }
  if(b==length(thresholdBreaks)-1){
    rm(tempDat)
  }
}

thresholdSumsDf$threshold_f <- factor(thresholdSumsDf$threshold)

# Calculate proportional value
thresholdTotals <- thresholdSumsDf %>%
  group_by(threshold_f) %>%
  summarise(thresholdTotal = sum(n))

thresholdSumsDf <- merge(thresholdSumsDf, thresholdTotals)

thresholdSumsDf <- thresholdSumsDf %>%
  mutate(proportion = n/thresholdTotal)



## Format aesthetics for plotting
# Read in the aethetics for oro_type 
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
thresholdSumsDf$oro_type <- factor(
  thresholdSumsDf$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Merge sums with plotting order, colour 
typeAES$oro_type <- typeAES$label
thresholdSumsDf <- merge(thresholdSumsDf,typeAES[,c("oro_type","order","colour")])
# thresholdSumsDf$order <- factor(thresholdSumsDf$order,
#                             levels = thresholdSumsDf$order[order(thresholdSumsDf$order)])



# Plot
oroDistOverThresholdWindow_ggp <- ggplot(data=thresholdSumsDf, aes(x=threshold_f, y=proportion))+
  geom_col(aes(fill=oro_type), position ="stack")+
  geom_text(aes(x=threshold_f, label = thresholdTotal), y=1.01, vjust = 0.5, hjust=0, check_overlap = TRUE, inherit.aes = FALSE, size=3, angle = 90)+
  scale_fill_manual(values = typeAES$colour, name = "ORO type")+
  labs(x = "Threshold", y= "Proportion of articles")+
  ylim(0, 1.1)+
  theme_bw()+
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

oroDistOverThresholdWindow_ggp



ggsave(
  here::here("figures/supplemental/distributionOROTypesBinnedRelevanceThresholds.pdf"),
  plot = oroDistOverThresholdWindow_ggp,
  width = 7, height = 5, units = "in"
)

```




```{r chi-sq test to see if changing the relevance threshold results in difference from 0.5}
# See: https://iastate.pressbooks.pub/quantitativeplantbreeding/chapter/categorical-data-multivariate/
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8038644/

# Calculate the expected proportions to test agains (when threshold is 0.5)
nullProp <- thresholdSensitivityDf %>%
  filter(0.5 <= relevance_mean) %>%
      group_by(oro_type) %>%
      summarise(
        null_n = sum(0.5 <= mean)
        )
nullProp$null_prop <- nullProp$null_n/sum(nullProp$null_n)


## Loop through the different thresholds
# Set breaks to loop through
thresholdBreaks <- seq(0.5,1, by=0.1)

for(b in 1:(length(thresholdBreaks)-1)){
  # calculate proportions above the new threshold
  tempDat <- thresholdSensitivityDf %>%
    filter(thresholdBreaks[b] <= relevance_mean) %>%
    group_by(oro_type) %>%
    summarise(
        n = sum(0.5 <= mean)
        ) %>%
    mutate(threshold = thresholdBreaks[b], breakOrder = b)
  tempDat$observed_prop <- tempDat$n/sum(tempDat$n)
  tempDat$total_articles <- sum(tempDat$n)
  # Test if the population probabilities are different from those found in the null (using relevance of 0.5)
  test <- chisq.test(x = tempDat$n, p = nullProp$null_prop)
  tempDat$chisq_pvalue <- test$p.value
  # Bind into a data frame
  if(b==1){
    thresholdChiSqDf <- tempDat
  }else{
    thresholdChiSqDf <- rbind(thresholdChiSqDf, tempDat)
  }
  if(b==length(thresholdChiSqDf)-1){
    rm(tempDat)
  }
}

summary(thresholdChiSqDf)


## Format aesthetics for plotting
# Read in the aethetics for oro_type 
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
thresholdChiSqDf$oro_type <- factor(
  thresholdChiSqDf$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Merge sums with plotting order, colour 
typeAES$oro_type <- typeAES$label
thresholdChiSqDf <- merge(thresholdChiSqDf,typeAES[,c("oro_type","order","colour")])



## Write results to csv
write.csv(thresholdChiSqDf, here::here("outputs/changingRelevanceThresholdSensitivityTest_chisq.csv"))

```

```{r bar plot changing proportions of oros as a function of changing threshold values}
oroDistOverThreshold_ggp <- ggplot(data=thresholdChiSqDf, aes(x=as.factor(threshold), y=observed_prop))+
  geom_col(aes(fill=oro_type), position ="stack")+
  geom_text(aes(x=as.factor(threshold), label = total_articles), y=1.01, vjust = 0, check_overlap = TRUE, inherit.aes = FALSE, size=4)+
  #geom_vline(xintercept = 6, col="red", linewidth = 1)+
  # if there is a significant difference add an asterisk
  geom_text(data = thresholdChiSqDf %>% filter(chisq_pvalue <= 0.05 & 0 < chisq_pvalue), aes(x=breakOrder),
            y=1.05, hjust=0, label = "*", inherit.aes = FALSE, col="red")+
  scale_fill_manual(values = typeAES$colour, name = "ORO type")+
  labs(x = "Threshold", y= "Proportion of articles")+
  ylim(0, 1.02)+
  theme_bw()+
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
oroDistOverThreshold_ggp

ggsave(
  here::here("figures/supplemental/changingRelevanceThresholdSensitivityTest.pdf"),
  plot = oroDistOverThreshold_ggp,
  width = 7, height = 5, units = "in"
)
```

## other less suitable approaches I tried

Permuation test I dont think I coded correctly -- shuffling would work if I was testing agains completely random null, but not with expected proportions.
```{r PERMUTATION of chi-sq test to see if changing the relevance threshold results in difference from 0.5}
# See: https://iastate.pressbooks.pub/quantitativeplantbreeding/chapter/categorical-data-multivariate/
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8038644/


## Define functions and parameters for permutations

nperms <- 5000 # number of permutations to run

# # Function to generate a permutation sample and compute its chi-squared statistic
# perm_stat <- function(observed_prop, expected_prop, size) {
#   perm_sample <- rep(0, length(observed_prop))
#   for(o in 1:length(observed_prop)){
#     perm_sample[o] <- rbinom(1, size, observed_prop[o])
#   }
#   
#   observed <- observed_prop*size
#   #expected <- expected_prop*sum(perm_sample)
#   expected <- expected_prop*size
#   perm_sample <- sample(observed, size = length(observed), replace = FALSE)
#   chi_sq_perm <- sum((perm_sample - expected)^2 / expected)
#   return(chi_sq_perm)
# }
#   
# 
# # Function to perform permutation test for a given number of permutations
# perm_test_chisq <- function(observed_prop, expected_prop, size, nperms = 500) {
#   # Calculate the expected frequencies
#   observed <- observed_prop*size
#   expected <- expected_prop*size
#   # Perform the chi-squared test on the observed data
#   chi_sq_obs <- sum((observed - expected)^2 / expected)
#   # Generate permutation samples and calculate chi-squared statistics
#   perm_stats <- replicate(nperms, perm_stat(observed_prop, expected_prop, size))
#   # Calculate the p-value as the proportion of permuted chi-squared stats
#   # that are less than or equal to the observed chi-squared stat
#   p_value_right <- sum(perm_stats <= chi_sq_obs)/nperms
#   p_value_left <- sum(chi_sq_obs <= perm_stats)/nperms
#   
#   # Return two-sided permuted p value using the criteria in
#   # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.permutation_test.html
#   return(min(c(p_value_right, p_value_left))*2)
# }


# Calculate the expected proportions to test against (when threshold is 0.5)
nullProp <- thresholdSensitivityDf %>%
  filter(0.5 <= relevance_mean) %>%
      group_by(oro_type) %>%
      summarise(
        null_n = sum(0.5 <= mean)
        )
nullProp$null_prop <- nullProp$null_n/sum(nullProp$null_n)


# Use this to simulate a null distribution of the chisq of expected proportions
perm_stat <- function(expected_prop, size) {
  perm_sample <- rep(0, length(expected_prop))
  for(o in 1:length(expected_prop)){
    perm_sample[o] <- rbinom(1, size, expected_prop[o])
  }
  expected <- expected_prop*sum(perm_sample)
  chi_sq_perm <- sum((perm_sample - expected)^2 / expected)
  return(chi_sq_perm)
}
perm_stats <- replicate(nperms, perm_stat(nullProp$null_prop, sum(nullProp$null_n)))
hist(perm_stats)



## Loop through the different thresholds
# Set breaks to loop through
thresholdBreaks <- seq(0.5,1, by=0.1)
#thresholdBreaks <- thresholdBreaks[thresholdBreaks != 0.5]

for(b in 1:(length(thresholdBreaks)-1)){
  # calculate counts above the new threshold
  tempDat <- thresholdSensitivityDf %>%
    filter(thresholdBreaks[b] <= relevance_mean) %>%
    group_by(oro_type) %>%
    summarise(
        n = sum(0.5 <= mean)
        ) %>%
    mutate(threshold = thresholdBreaks[b], breakOrder = b) %>%
    left_join(nullProp, by = "oro_type")
  tempDat$observed_prop <- tempDat$n/sum(tempDat$n)
  tempDat$total_articles <- sum(tempDat$n)
  
  # Test if the counts are different from those found in the null (using relevance of 0.5)
  # observed_prop = tempDat$observed_prop
  # expected_prop = tempDat$null_prop
  # size = sum(tempDat$n)
  # tempDat$chisq_pvalue <- perm_test_chisq(observed_prop, expected_prop, size, nperms)
  observed <- tempDat$n
  expected <- nullProp$null_prop*sum(tempDat$n)
  chi_sq_obs <- sum((observed - expected)^2 / expected)
  tempDat$chi_sq_obs <- chi_sq_obs
  
  # Calculate the p-value as the proportion of permuted chi-squared stats
  # that are less than or equal to the observed chi-squared stat
  p_value_right <- sum(perm_stats <= chi_sq_obs)/nperms
  p_value_left <- sum(chi_sq_obs <= perm_stats)/nperms
  #tempDat$chisq_pvalue <- min(c(p_value_right, p_value_left))*2
  tempDat$chisq_pvalue <- p_value_left

  
  # Bind into a data frame
  if(b==1){
    thresholdChiSqDf <- tempDat
  }else{
    thresholdChiSqDf <- rbind(thresholdChiSqDf, tempDat)
  }
  if(b==length(thresholdChiSqDf)-1){
    rm(tempDat)
  }
}

summary(thresholdChiSqDf)


## Format aesthetics for plotting
# Read in the aethetics for oro_type 
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
thresholdChiSqDf$oro_type <- factor(
  thresholdChiSqDf$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Merge sums with plotting order, colour 
typeAES$oro_type <- typeAES$label
thresholdChiSqDf <- merge(thresholdChiSqDf,typeAES[,c("oro_type","order","colour")])





## Write results to csv
write.csv(thresholdChiSqDf, here::here("outputs/changingRelevanceThresholdSensitivityTest_permutation.csv"))

```



```{r bar plot changing proportions of oros as a function of changing threshold values}
oroDistOverThresholdPerm_ggp <- ggplot(data=thresholdChiSqDf, aes(x=as.factor(threshold), y=observed_prop))+
  geom_col(aes(fill=oro_type), position ="stack")+
  geom_text(aes(x=as.factor(threshold), label = total_articles), y=1.01, vjust = 0, check_overlap = TRUE, inherit.aes = FALSE, size=4)+
  #geom_vline(xintercept = 6, col="red", linewidth = 1)+
  # if there is a significant difference add an asterisk
  geom_text(data = thresholdChiSqDf %>% filter(chisq_pvalue <= 0.05), aes(x=breakOrder),
            y=1.04, hjust=0.5, label = "*", inherit.aes = FALSE, col="red")+
  scale_fill_manual(values = typeAES$colour, name = "ORO type")+
  labs(x = "Threshold", y= "Proportion of articles")+
  ylim(0, 1.02)+
  theme_bw()+
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
oroDistOverThresholdPerm_ggp

ggsave(
  here::here("figures/supplemental/changingRelevanceThresholdSensitivityTest_permutation.pdf"),
  plot = oroDistOverThresholdPerm_ggp,
  width = 7, height = 5, units = "in"
)
```


I looked into anova or permanova but you need multiple samples per threshold, and I only have one

```{r ANOVA test to see if changing the relevance threshold results in difference from 0.5, eval = FALSE}

require(vegan)

nullProp <- thresholdSensitivityDf %>%
      group_by(oro_type) %>%
      summarise(
        n = sum(0.5 <= relevance_mean)
        )
nullProp$prop <- nullProp$n/sum(nullProp$n)

# Set breaks to loop through
thresholdBreaks <- seq(0,1, by=0.1)

for(b in 1:(length(thresholdBreaks)-1)){
  # calculate proportions above the new threshold
  tempDat <- thresholdSensitivityDf %>%
    group_by(oro_type) %>%
    summarise(
        n = sum(thresholdBreaks[b] <= relevance_mean)
        ) %>%
    mutate(threshold = thresholdBreaks[b], breakOrder = b)
  tempDat$prop <- tempDat$n/sum(tempDat$n)
  
  # Test if the population probabilities are different from those found in the null (using relevance of 0.5)
  # ANOVA 
  # make new data frame
  newDat <- nullProp %>%
    mutate(threshold = 0.5)%>%
    rbind(tempDat %>% select(oro_type, n, prop, threshold))
  
  test <- aov(prop ~ as.factor(threshold), data = newDat)
  summary(test)
  test <- summary(test)
  tempDat$pvalue <- test[[1]]$`Pr(>F)`[1]
  
  # Bind into a data frame
  if(b==1){
    thresholdTestDf <- tempDat
  }else{
    thresholdTestDf <- rbind(thresholdTestDf, tempDat)
  }
  if(b==length(thresholdTestDf)-1){
    rm(tempDat)
  }
}

summary(thresholdTestDf)


## Format aesthetics for plotting
# Read in the aethetics for oro_type 
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
thresholdTestDf$oro_type <- factor(
  thresholdTestDf$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Merge sums with plotting order, colour 
typeAES$oro_type <- typeAES$label
thresholdTestDf <- merge(thresholdTestDf,typeAES[,c("oro_type","order","colour")])



```


```{r PERMANOVA test to see if changing the relevance threshold results in difference from 0.5, eval = FALSE}

require(vegan)

# Set breaks to loop through
thresholdBreaks <- seq(0,1, by=0.1)

for(b in 1:(length(thresholdBreaks)-1)){
  # calculate proportions above the new threshold
  tempDat <- thresholdSensitivityDf %>%
    group_by(oro_type) %>%
    summarise(
        n = sum(thresholdBreaks[b] <= relevance_mean)
        ) 
  tempDat$prop <- tempDat$n/sum(tempDat$n)
  
  
  # Bind into a data frame
  if(b==1){
    thresholdTestDf <- tempDat$n
  }else{
    thresholdTestDf <- rbind(thresholdTestDf, tempDat$n)
  }
}

thresholdTestMat <- as.matrix(thresholdTestDf)
colnames(thresholdTestMat) <- tempDat$oro_type
threshDist <- vegdist(thresholdTestMat, method='bray')


thresholdTestDf <- as.data.frame(thresholdTestDf)
colnames(thresholdTestDf) <- tempDat$oro_type
thresholdTestDf$threshold <- thresholdBreaks[1:(length(thresholdBreaks)-1)]

## Calculate distances using bray-curtis (abundance-weighted)

set.seed(123) #reproducible results
thresh.div<-adonis2(threshDist~as.factor(threshold), data = thresholdTestDf, permutations=9999)
thresh.div




## Format aesthetics for plotting
# Read in the aethetics for oro_type 
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
# Use to factor oro_type column
thresholdTestDf$oro_type <- factor(
  thresholdTestDf$oro_type, 
  levels = typeAES$level, labels = typeAES$label
)

# Merge sums with plotting order, colour 
typeAES$oro_type <- typeAES$label
thresholdTestDf <- merge(thresholdTestDf,typeAES[,c("oro_type","order","colour")])


```













# Supplementary figure: Timeline of blue carbon tag
```{r Sum n articles per mitigation ORO per year}
predRel <- tbl(dbcon, "pred_relevance") %>%
  filter(thresholdLevel <= relevance_mean) %>%
  select(analysis_id)
predBC <- tbl(dbcon, "pred_blue_carbon")%>%
  rename(mean = `0 - relevance - mean_prediction`, 
         lower = `0 - relevance - lower_pred`,
         upper = `0 - relevance - upper_pred`) %>%
  select(analysis_id, mean, upper, lower) %>%
  filter(thresholdLevel <= mean) 
uniquerefs <- tbl(dbcon, "uniquerefs")

## Format and collect needed data
predBCDf <- predRel %>%
  inner_join(predBC, by ="analysis_id") %>%
  left_join(uniquerefs %>% select(analysis_id, year), by = "analysis_id") %>%
  collect()



BC_by_year_sums <- predBCDf %>%
  filter(1980 <= year) %>%
  group_by(year)%>%
  summarise(
    mean = sum(thresholdLevel <= mean),
    lower = sum(thresholdLevel <= lower),
    upper = sum(thresholdLevel <= upper)
  ) 


# Factor and format
BC_by_year_sums <- BC_by_year_sums%>%
  na.omit() %>%
  mutate(year = as.Date(paste0(year, "-01-01")))

summary(BC_by_year_sums)


# text labels
BC_text <- BC_by_year_sums %>%
  filter(year == as.Date("2020-01-01")) 

```

```{r PLOT timeline of mitigation OROs to compare to De Pryk and Boettcher 2023 -- NOT LOGGED}

Sfig_BC_ggp <- ggplot()+
  geom_ribbon(data = BC_by_year_sums, 
              aes(x=year, ymin = lower, ymax=upper), alpha = 0.5, fill = "turquoise")+
  geom_line(data = BC_by_year_sums, aes(x=year, y=mean), 
            linewidth = 1,
            na.rm=T, col = "turquoise4")+
  geom_text(data= BC_text, 
            aes(x=year, y=upper, label = stringr::str_wrap("Blue carbon", width=30)),
            vjust = "outward", hjust="inward", size=3, col="black")+

  # Format scales
  labs(x="Year", y="N articles")+
  scale_x_date(limits = c(as.Date("1980-01-01"),as.Date("2022-12-31")))+
 
  theme_classic()+
  theme(
    legend.position = "none",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )


Sfig_BC_ggp

ggsave(here::here("figures/supplemental/blueCarbonTimeline_DePryckAndBoettcher2024Compare.pdf"), width=6, height=4, units="in")
```


```{r PLOT timeline of Blue carbon OROs logged version}

Sfig_BC_ggp <- ggplot()+
  geom_ribbon(data = BC_by_year_sums, 
              aes(x=year, ymin = log(lower), ymax=log(upper)), alpha = 0.5)+
  geom_line(data = BC_by_year_sums, aes(x=year, y=log(mean)), 
            linewidth = 1,
            na.rm=T)+
  geom_text(data= BC_text, 
            aes(x=year, y=log(upper), label = stringr::str_wrap("Blue carbon", width=30)),
            vjust = "outward", hjust="inward", size=3, col="black")+

  # Format scales
  labs(x="Year", y="log(N articles)")+
  scale_x_date(limits = c(as.Date("1980-01-01"),max(BC_by_year_sums$year)))+
  scale_y_continuous(sec.axis = sec_axis(trans = exp, name = "N articles", 
                                         breaks = seq(0,500,by=100),
                                         labels = function(x) formatC(x, big.mark=",", format="d")),
                     breaks = seq(0,10, by= 2))+
  theme_classic()+
  theme(
    legend.position = "none",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )


Sfig_BC_ggp


```




