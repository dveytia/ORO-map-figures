---
title: "OSM_figures"
author: "Devi Veytia"
date: "2024-02-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up

```{r load libraries}
library(dplyr)
library(dbplyr)
library(R.utils)
library(RSQLite)
library(ggplot2)
```


```{r Get the latest version of sqlite database and connect}

sqliteDir <- here::here("data/sqlite-databases")
sqliteFiles <- dir(sqliteDir)
sqliteVersions <- as.numeric(gsub(".sqlite","",substring(sqliteFiles, regexpr("_v", sqliteFiles) + 2)))
latestVersion <- sqliteFiles[which.max(sqliteVersions)]
dbcon <- RSQLite::dbConnect(RSQLite::SQLite(), file.path(sqliteDir, latestVersion), create=FALSE)
```


```{r import common aesthetics}
factor_aes <- readxl::read_excel(here::here("R/factor_aesthetics.xlsx"))
```

# Figure 1: Line plot of # articles for Ocean & climate research, all OROs, and NbS by year

For each year, count the number of lower, mean and upper articles relevant for all OROs and for each branch
```{r Sum n articles per oro branch per year}
predRel <- tbl(dbcon, "pred_relevance") 
pred_oro_branch <- tbl(dbcon, "pred_oro_branch")
uniquerefs <- tbl(dbcon, "allrefs")

oro_branch_by_year <- pred_oro_branch %>%
  inner_join(predRel %>% select(analysis_id, relevance_mean), by = "analysis_id")%>%
  filter(0.5 <= relevance_mean) %>% 
  inner_join(uniquerefs %>% select(analysis_id, year), by = "analysis_id") %>%
  group_by(year) %>%
  summarise(
    allORO_mean = sum(0.5 <= `oro_branch.Mitigation - mean_prediction` |
                        0.5 <= `oro_branch.Nature - mean_prediction` |
                        0.5 <= `oro_branch.Societal - mean_prediction`),
    allORO_lower = sum(0.5 <= `oro_branch.Mitigation - lower_pred` |
                        0.5 <= `oro_branch.Nature - lower_pred` |
                        0.5 <= `oro_branch.Societal - lower_pred`),
    allORO_upper = sum(0.5 <= `oro_branch.Mitigation - upper_pred` |
                        0.5 <= `oro_branch.Nature - upper_pred` |
                        0.5 <= `oro_branch.Societal - upper_pred`),
    Mitigation_mean = sum(0.5 <= `oro_branch.Mitigation - mean_prediction`),
    Mitigation_lower = sum(0.5 <= `oro_branch.Mitigation - lower_pred`),
    Mitigation_upper = sum(0.5 <= `oro_branch.Mitigation - upper_pred`),
    Nature_mean = sum(0.5 <= `oro_branch.Nature - mean_prediction`),
    Nature_lower = sum(0.5 <= `oro_branch.Nature - lower_pred`),
    Nature_upper = sum(0.5 <= `oro_branch.Nature - upper_pred`),
    Societal_mean = sum(0.5 <= `oro_branch.Societal - mean_prediction`),
    Societal_lower = sum(0.5 <= `oro_branch.Societal - lower_pred`),
    Societal_upper = sum(0.5 <= `oro_branch.Societal - upper_pred`)
  ) %>% 
  collect()

# Melt and reformat so each line is a yearxbranch, and then columns for mean, lower and upper
variables <- c("allORO","Mitigation","Nature","Societal")

for(v in 1:length(variables)){
  sub <- oro_branch_by_year[,c(1,grep(variables[v], colnames(oro_branch_by_year)))]
  colnames(sub) <- gsub(paste0(variables[v],"_"),"", colnames(sub))
  # sub <- reshape2::melt(sub, id.vars = "year", variable.name = "prediction_boundary", 
  #                       value.name = "n_articles")
  sub$ORO_branch <- paste(variables[v])
  if(v==1){
    oro_branch_by_year_sums <- sub
  }else{
    oro_branch_by_year_sums <- rbind(oro_branch_by_year_sums, sub)
  }
}


# Limit to just all OROs and NbS and format year as Date
oro_branch_by_year_sums <- oro_branch_by_year_sums%>%
  na.omit() %>%
  filter(ORO_branch %in% c("allORO","Nature")) %>%
  mutate(year = as.Date(paste0(year, "-01-01")),
         ORO_branch = factor(ORO_branch, levels = c("allORO","Nature"), labels=c("All OROs","NbS")))


# use the max year to set the x limits
xmax = as.Date("2022-12-31")
xmin = as.Date("1980-01-01")

oro_branch_by_year_sums <- oro_branch_by_year_sums %>%
  filter(xmin <= year & year <= xmax)
```

```{r get number of articles from citation indexed databases}

## Web of Science
wos_by_year <- read.delim2(
  here::here("data/external/ocean-and-climate-publications/WOS_ocean-and-climate_by-year_2023-11-21.txt"))

wos_by_year <- wos_by_year %>%
  rename(year = Publication.Years, n_articles = Record.Count)%>%
  select(year, n_articles)%>%
  mutate(year = as.Date(paste0(year, "-01-01"))) %>%
  filter(as.Date("1991-01-01") <= year & year <= xmax) %>%
  na.omit()


## Scopus
scopus_by_year <- read.csv(
  here::here("data/external/ocean-and-climate-publications/SCOPUS_ocean-and-climate_by-year_2023-11-21.csv"))

scopus_by_year <- scopus_by_year %>%
  mutate(year = as.Date(paste0(year, "-01-01"))) %>%
  filter(xmin <= year & year <= xmax)%>%
  na.omit()


```


```{r fit log-transformed lm log(y) = log(a) + r * t to estimate rate of change for each dataset}
# Create one dataset with all the information
modDf <- rbind(
  cbind(wos_by_year, dataset = "WOS"),
  cbind(scopus_by_year, dataset = "Scopus"),
  oro_branch_by_year_sums %>% select(year, mean, ORO_branch) %>% rename(n_articles = mean, dataset = ORO_branch)
)

# Subset to only common years?
modDf <- subset(modDf, year %in% as.Date(intersect(intersect(wos_by_year$year,scopus_by_year$year),oro_branch_by_year_sums$year), origin = "1970-01-01"))

modDf <- na.omit(modDf)

modDf$dataset <- factor(modDf$dataset, levels = c("WOS","Scopus","All OROs","NbS"))
summary(modDf)


# Fit seperate log-transformed model for each group
fits <- plyr::dlply(modDf, "dataset", function(df) lm(log(n_articles) ~ year, data=df))
fits_df <- plyr::ldply(fits, coef) %>% as.data.frame()
pVal_df = plyr::ldply(fits, function(x) summary(x)$coefficients["year","Pr(>|t|)"]) %>% as.data.frame()
colnames(pVal_df)[2] <- "pVal"
rSq_df <- plyr::ldply(fits, function(x) summary(x)$r.squared) %>% as.data.frame()
colnames(rSq_df)[2] <- "r2"
fits_df <- merge(fits_df, pVal_df)
fits_df <- merge(fits_df, rSq_df)
fits_df <- fits_df %>% rename(rate = year)

maxYear <- modDf %>% filter(year == as.Date("2022-01-01"))
fits_df <- merge(fits_df, maxYear)

# # Format numbers for readability?
# fits_df[,c("year","pVal","r2")] <- apply(fits_df[,c("year","pVal","r2")], 1:2, function(x) formatC(x, digits=3, format = "E"))
```



```{r PLOT Figure 1}
fig1_ggp <- ggplot()+
  
  # Plot complete years
  geom_ribbon(data = oro_branch_by_year_sums, 
              aes(x=year, ymin = log(lower), ymax=log(upper), fill = ORO_branch), alpha = 0.5)+
  geom_line(data = oro_branch_by_year_sums, aes(x=year, y=log(mean), col=ORO_branch), linewidth = 1,
            na.rm=T)+
  geom_line(data = wos_by_year, 
            aes(x=year, y=log(n_articles), linetype = "WOS"), col="black", linewidth = 1,
            na.rm=T)+
  geom_line(data = scopus_by_year, 
            aes(x=year, y=log(n_articles), linetype = "Scopus"), col="black", linewidth = 1,
            na.rm=T)+
  
  # Plot model rates
  geom_text(data = fits_df %>% filter(dataset != "WOS"), aes(x = year, y = log(n_articles)-0.7, 
                                label = paste("r =",formatC(rate, digits=2, format="E"))),
            col = "red",size=3)+
  
  # Format scales
  scale_color_manual(values = c("navy", "forestgreen"), 
                     name = "ORO type", guide=guide_legend(order=1, nrow=2), position = "top")+
  scale_fill_manual(values = c("navy", "forestgreen"), guide = "none")+
  scale_linetype_manual(values = c("solid","dotted"), name = "Oceans & climate literature\ndatabase:",
                        guide=guide_legend(order=2, nrow=2), position = "bottom")+
  labs(x="Year", y="log(N articles)/year")+
  scale_x_date(limits = c(as.Date("1980-01-01"),xmax+300))+
  scale_y_continuous(sec.axis = sec_axis(trans = exp, name = "N articles", 
                                         breaks = c(0,100,1000,10000,30000,80000),
                                         labels = function(x) formatC(x, big.mark=",", format="d")),
                     breaks = seq(0,10, by= 2))+
  theme_classic()+
  theme(
    legend.position = "bottom",
    legend.box = "vertical",
    legend.text = element_text(size=8),
    legend.title = element_text(size=10),
    axis.text = element_text(size=7)
    )

fig1_ggp
```


# Figure 3 - upset plot just showing interactions with NbS



```{r calculate oro-oro interaction sizes}
predRel <- tbl(dbcon, "pred_relevance") %>%
  filter(0.5 <= relevance_mean) %>%
  select(analysis_id)
predType <- tbl(dbcon, "pred_oro_type_long") %>%
  filter(0.5 <= mean) %>%
  select(analysis_id, oro_type)

## Join together to get relevance preditions for all included
oroTypeDf <- predRel %>%
  inner_join(predType, by ="analysis_id") %>% 
  collect()

# Format aesthetics for plotting
typeAES <- factor_aes[which(factor_aes$variable == "oro_type"),]
typeAES <- typeAES[order(typeAES$order),]
typeAES$label[which(typeAES$label == "Conservation")] <- "Conservation/NbS"

oroTypeDf <- oroTypeDf %>%
  mutate(oro_type = factor(oro_type, levels = typeAES$level, labels = typeAES$label))

# format as tabular data
oroTypeDf_wide <- oroTypeDf %>%
  select(analysis_id, oro_type) %>%
  mutate(count = 1) %>%
  reshape2::dcast(analysis_id ~ oro_type, drop=FALSE, value.var = "count")

upsetCols <- typeAES %>%
  rename(set = label, fill = colour) %>%
  select(set, fill)


# Also calculate interaction matrix
oroTypeDf_mat <- crossprod(table(oroTypeDf[,c("analysis_id","oro_type")]))

# set buckets that aren't crossed with conservation to 0
for(i in 1:nrow(oroTypeDf_mat))
  for(j in 1:ncol(oroTypeDf_mat))
    if(grepl("conservation", rownames(oroTypeDf_mat)[i], ignore.case = TRUE) |
       grepl("conservation", colnames(oroTypeDf_mat)[j], ignore.case = TRUE)){
      oroTypeDf_mat[i,j] <- oroTypeDf_mat[i,j]
    } else{
      oroTypeDf_mat[i,j] <- 0
    } 

```

```{r save upset plot}
require(ComplexUpset)

vars = colnames(oroTypeDf_wide)[colnames(oroTypeDf_wide) != "analysis_id"]

# Get the names of all the interaction combinations that include conservation
allIntersections2D <- t(combn(vars,2))
allIntersections2D <- allIntersections2D[apply(allIntersections2D, 1, function(x) grepl("conservation", paste(x, collapse = ""), ignore.case=T)),]

allIntersections3D <- t(combn(vars,3))
allIntersections3D <- allIntersections3D[apply(allIntersections3D, 1, function(x) grepl("conservation", paste(x, collapse = ""), ignore.case=T)),]

allIntersections4D <- t(combn(vars,4))
allIntersections4D <- allIntersections4D[apply(allIntersections4D, 1, function(x) grepl("conservation", paste(x, collapse = ""), ignore.case=T)),]

# Plot the upset plot
upset(
  data=oroTypeDf_wide,
  intersect = rev(colnames(oroTypeDf_wide)[colnames(oroTypeDf_wide) != "analysis_id"]),
  intersections = c(as.list(data.frame(t(allIntersections2D))),
                    as.list(data.frame(t(allIntersections3D))),
                    as.list(data.frame(t(allIntersections4D)))),
  width_ratio = 0.3,
  min_size = 1,
  keep_empty_groups = FALSE,
  sort_sets = FALSE,
  base_annotations = list('Intersection size' = intersection_size(text = list(size=3.5))+
                            ylim(c(0,600))), #, vjust=-0.1, hjust=-0.1, angle=45
  set_sizes = (upset_set_size(geom = geom_bar(fill = "white"))+
                 geom_text(aes(label=..count..), hjust=1.1, stat='count', size=3, col="white")+
                 expand_limits(y=30000)+
                 theme(axis.text.x = element_text(angle=90))),
  stripes = rev(typeAES$colour),
  sort_intersections = 'ascending',
  sort_intersections_by = c("degree","cardinality"),
  group_by = "degree",
  min_degree = 2,
  max_degree = 3,
  # highlight interesting interactions
  queries = list(
    upset_query(intersect = c("CO2 removal or storage", "Conservation/NbS"), color = "orange", fill="orange"),
    upset_query(intersect = c("Built infrastructure & technology", "Conservation/NbS"), color = "orange", fill="orange"),
    upset_query(intersect = c("Conservation/NbS", "Built infrastructure & technology","Socio-institutional"), color = "orange", fill="orange")
  )
)

# save fig dimensions: 800 x 470
# for pdf 9 x 5 in
```








